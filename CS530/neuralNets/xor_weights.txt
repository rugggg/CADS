Doug Woodward

50,000 Epochs: -> changing number of epochs results in the same situation of differing weights, the error does converge to 0
    Turns out training the NN multiple times over gives entirely different weights each time - with little pattern. Here's a sample of three:

       Layer 1 Weights: [-7.03211826,  3.82116327, -3.91333506, -0.9573649 ],
                        [-7.09748612,  3.72304738, -3.82400607, -1.47264798],
                        [ 3.09978302, -5.84207382,  5.98163626,  1.75156214]
       Layer 2 Weights: [-13.65548219],
                        [ -8.17205721],
                        [  6.41662039],
                        [  1.48637477]

        Error:0.00473478014015


        Layer 1: [ 7.06006264,  6.43215435,  0.94607107,  0.30265384],
                 [-6.58270918, -6.83187112, -0.78397364,  0.91486532],
                 [ 3.22423295, -3.41951694, -0.85045908,  2.34045843]
        Layer 2: [-11.75623677],
                 [ 11.69907379],
                 [  1.66035359],
                 [  5.49619834]

        Error:0.00545158081337


        Layer 1: [-2.40139511,  7.04294843, -3.79506566,  5.76510983],
                 [-2.36320275, -4.6449124 ,  6.85672616,  5.6015008 ],
                 [ 3.52673518,  1.70724685,  1.04196897, -1.52593044]
        Layer 2: [  5.92126436],
                 [ -8.61436695],
                 [ -8.71472732],
                 [ 10.35567652]

        Error:0.00414385749971


